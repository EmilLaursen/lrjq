// Code generated by pggen. DO NOT EDIT.

package gen

import (
	"context"
	"fmt"
	"github.com/jackc/pgconn"
	"github.com/jackc/pgtype"
	"github.com/jackc/pgx/v4"
)

// Querier is a typesafe Go interface backed by SQL queries.
//
// Methods ending with Batch enqueue a query to run later in a pgx.Batch. After
// calling SendBatch on pgx.Conn, pgxpool.Pool, or pgx.Tx, use the Scan methods
// to parse the results.
type Querier interface {
	Enqueue(ctx context.Context, params EnqueueParams) (EnqueueRow, error)
	// EnqueueBatch enqueues a Enqueue query into batch to be executed
	// later by the batch.
	EnqueueBatch(batch genericBatch, params EnqueueParams)
	// EnqueueScan scans the result of an executed EnqueueBatch query.
	EnqueueScan(results pgx.BatchResults) (EnqueueRow, error)

	Dequeue(ctx context.Context, queueID string) (DequeueRow, error)
	// DequeueBatch enqueues a Dequeue query into batch to be executed
	// later by the batch.
	DequeueBatch(batch genericBatch, queueID string)
	// DequeueScan scans the result of an executed DequeueBatch query.
	DequeueScan(results pgx.BatchResults) (DequeueRow, error)

	ReportDone(ctx context.Context, id int32, workSignature pgtype.UUID) (pgconn.CommandTag, error)
	// ReportDoneBatch enqueues a ReportDone query into batch to be executed
	// later by the batch.
	ReportDoneBatch(batch genericBatch, id int32, workSignature pgtype.UUID)
	// ReportDoneScan scans the result of an executed ReportDoneBatch query.
	ReportDoneScan(results pgx.BatchResults) (pgconn.CommandTag, error)

	RequeueFailed(ctx context.Context, deadline pgtype.Interval) (pgconn.CommandTag, error)
	// RequeueFailedBatch enqueues a RequeueFailed query into batch to be executed
	// later by the batch.
	RequeueFailedBatch(batch genericBatch, deadline pgtype.Interval)
	// RequeueFailedScan scans the result of an executed RequeueFailedBatch query.
	RequeueFailedScan(results pgx.BatchResults) (pgconn.CommandTag, error)

	DeleteDeadLetters(ctx context.Context, maxTries int32) (pgconn.CommandTag, error)
	// DeleteDeadLettersBatch enqueues a DeleteDeadLetters query into batch to be executed
	// later by the batch.
	DeleteDeadLettersBatch(batch genericBatch, maxTries int32)
	// DeleteDeadLettersScan scans the result of an executed DeleteDeadLettersBatch query.
	DeleteDeadLettersScan(results pgx.BatchResults) (pgconn.CommandTag, error)

	SendHeartBeat(ctx context.Context, id int32, workSignature pgtype.UUID) (pgconn.CommandTag, error)
	// SendHeartBeatBatch enqueues a SendHeartBeat query into batch to be executed
	// later by the batch.
	SendHeartBeatBatch(batch genericBatch, id int32, workSignature pgtype.UUID)
	// SendHeartBeatScan scans the result of an executed SendHeartBeatBatch query.
	SendHeartBeatScan(results pgx.BatchResults) (pgconn.CommandTag, error)
}

type DBQuerier struct {
	conn  genericConn   // underlying Postgres transport to use
	types *typeResolver // resolve types by name
}

var _ Querier = &DBQuerier{}

// genericConn is a connection to a Postgres database. This is usually backed by
// *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
type genericConn interface {
	// Query executes sql with args. If there is an error the returned Rows will
	// be returned in an error state. So it is allowed to ignore the error
	// returned from Query and handle it in Rows.
	Query(ctx context.Context, sql string, args ...interface{}) (pgx.Rows, error)

	// QueryRow is a convenience wrapper over Query. Any error that occurs while
	// querying is deferred until calling Scan on the returned Row. That Row will
	// error with pgx.ErrNoRows if no rows are returned.
	QueryRow(ctx context.Context, sql string, args ...interface{}) pgx.Row

	// Exec executes sql. sql can be either a prepared statement name or an SQL
	// string. arguments should be referenced positionally from the sql string
	// as $1, $2, etc.
	Exec(ctx context.Context, sql string, arguments ...interface{}) (pgconn.CommandTag, error)
}

// genericBatch batches queries to send in a single network request to a
// Postgres server. This is usually backed by *pgx.Batch.
type genericBatch interface {
	// Queue queues a query to batch b. query can be an SQL query or the name of a
	// prepared statement. See Queue on *pgx.Batch.
	Queue(query string, arguments ...interface{})
}

// NewQuerier creates a DBQuerier that implements Querier. conn is typically
// *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
func NewQuerier(conn genericConn) *DBQuerier {
	return NewQuerierConfig(conn, QuerierConfig{})
}

type QuerierConfig struct {
	// DataTypes contains pgtype.Value to use for encoding and decoding instead
	// of pggen-generated pgtype.ValueTranscoder.
	//
	// If OIDs are available for an input parameter type and all of its
	// transitive dependencies, pggen will use the binary encoding format for
	// the input parameter.
	DataTypes []pgtype.DataType
}

// NewQuerierConfig creates a DBQuerier that implements Querier with the given
// config. conn is typically *pgx.Conn, pgx.Tx, or *pgxpool.Pool.
func NewQuerierConfig(conn genericConn, cfg QuerierConfig) *DBQuerier {
	return &DBQuerier{conn: conn, types: newTypeResolver(cfg.DataTypes)}
}

// WithTx creates a new DBQuerier that uses the transaction to run all queries.
func (q *DBQuerier) WithTx(tx pgx.Tx) (*DBQuerier, error) {
	return &DBQuerier{conn: tx}, nil
}

// preparer is any Postgres connection transport that provides a way to prepare
// a statement, most commonly *pgx.Conn.
type preparer interface {
	Prepare(ctx context.Context, name, sql string) (sd *pgconn.StatementDescription, err error)
}

// PrepareAllQueries executes a PREPARE statement for all pggen generated SQL
// queries in querier files. Typical usage is as the AfterConnect callback
// for pgxpool.Config
//
// pgx will use the prepared statement if available. Calling PrepareAllQueries
// is an optional optimization to avoid a network round-trip the first time pgx
// runs a query if pgx statement caching is enabled.
func PrepareAllQueries(ctx context.Context, p preparer) error {
	if _, err := p.Prepare(ctx, enqueueSQL, enqueueSQL); err != nil {
		return fmt.Errorf("prepare query 'Enqueue': %w", err)
	}
	if _, err := p.Prepare(ctx, dequeueSQL, dequeueSQL); err != nil {
		return fmt.Errorf("prepare query 'Dequeue': %w", err)
	}
	if _, err := p.Prepare(ctx, reportDoneSQL, reportDoneSQL); err != nil {
		return fmt.Errorf("prepare query 'ReportDone': %w", err)
	}
	if _, err := p.Prepare(ctx, requeueFailedSQL, requeueFailedSQL); err != nil {
		return fmt.Errorf("prepare query 'RequeueFailed': %w", err)
	}
	if _, err := p.Prepare(ctx, deleteDeadLettersSQL, deleteDeadLettersSQL); err != nil {
		return fmt.Errorf("prepare query 'DeleteDeadLetters': %w", err)
	}
	if _, err := p.Prepare(ctx, sendHeartBeatSQL, sendHeartBeatSQL); err != nil {
		return fmt.Errorf("prepare query 'SendHeartBeat': %w", err)
	}
	return nil
}

// JobStatus represents the Postgres enum "job_status".
type JobStatus string

const (
	JobStatusReady   JobStatus = "ready"
	JobStatusStarted JobStatus = "started"
	JobStatusDone    JobStatus = "done"
)

func (j JobStatus) String() string { return string(j) }

// typeResolver looks up the pgtype.ValueTranscoder by Postgres type name.
type typeResolver struct {
	connInfo *pgtype.ConnInfo // types by Postgres type name
}

func newTypeResolver(types []pgtype.DataType) *typeResolver {
	ci := pgtype.NewConnInfo()
	for _, typ := range types {
		if txt, ok := typ.Value.(textPreferrer); ok && typ.OID != unknownOID {
			typ.Value = txt.ValueTranscoder
		}
		ci.RegisterDataType(typ)
	}
	return &typeResolver{connInfo: ci}
}

// findValue find the OID, and pgtype.ValueTranscoder for a Postgres type name.
func (tr *typeResolver) findValue(name string) (uint32, pgtype.ValueTranscoder, bool) {
	typ, ok := tr.connInfo.DataTypeForName(name)
	if !ok {
		return 0, nil, false
	}
	v := pgtype.NewValue(typ.Value)
	return typ.OID, v.(pgtype.ValueTranscoder), true
}

// setValue sets the value of a ValueTranscoder to a value that should always
// work and panics if it fails.
func (tr *typeResolver) setValue(vt pgtype.ValueTranscoder, val interface{}) pgtype.ValueTranscoder {
	if err := vt.Set(val); err != nil {
		panic(fmt.Sprintf("set ValueTranscoder %T to %+v: %s", vt, val, err))
	}
	return vt
}

const enqueueSQL = `INSERT INTO queue.jobs (payload, priority, queue_id) VALUES
($1, $2, $3)
RETURNING *;`

type EnqueueParams struct {
	Payload  []byte
	Priority int32
	QueueID  string
}

type EnqueueRow struct {
	ID            int32              `json:"id"`
	QueueID       string             `json:"queue_id"`
	Payload       []byte             `json:"payload"`
	WorkSignature pgtype.UUID        `json:"work_signature"`
	CreatedAt     pgtype.Timestamptz `json:"created_at"`
	LastHeartbeat pgtype.Timestamptz `json:"last_heartbeat"`
	StartedAt     pgtype.Timestamptz `json:"started_at"`
	DoneAt        pgtype.Timestamptz `json:"done_at"`
	Tries         int32              `json:"tries"`
	Priority      int32              `json:"priority"`
	Status        JobStatus          `json:"status"`
}

// Enqueue implements Querier.Enqueue.
func (q *DBQuerier) Enqueue(ctx context.Context, params EnqueueParams) (EnqueueRow, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "Enqueue")
	row := q.conn.QueryRow(ctx, enqueueSQL, params.Payload, params.Priority, params.QueueID)
	var item EnqueueRow
	if err := row.Scan(&item.ID, &item.QueueID, &item.Payload, &item.WorkSignature, &item.CreatedAt, &item.LastHeartbeat, &item.StartedAt, &item.DoneAt, &item.Tries, &item.Priority, &item.Status); err != nil {
		return item, fmt.Errorf("query Enqueue: %w", err)
	}
	return item, nil
}

// EnqueueBatch implements Querier.EnqueueBatch.
func (q *DBQuerier) EnqueueBatch(batch genericBatch, params EnqueueParams) {
	batch.Queue(enqueueSQL, params.Payload, params.Priority, params.QueueID)
}

// EnqueueScan implements Querier.EnqueueScan.
func (q *DBQuerier) EnqueueScan(results pgx.BatchResults) (EnqueueRow, error) {
	row := results.QueryRow()
	var item EnqueueRow
	if err := row.Scan(&item.ID, &item.QueueID, &item.Payload, &item.WorkSignature, &item.CreatedAt, &item.LastHeartbeat, &item.StartedAt, &item.DoneAt, &item.Tries, &item.Priority, &item.Status); err != nil {
		return item, fmt.Errorf("scan EnqueueBatch row: %w", err)
	}
	return item, nil
}

const dequeueSQL = `WITH PEEK AS (
     SELECT id as peek_id
     FROM queue.jobs
     WHERE
        status = 'ready' and
        queue_id = $1
    ORDER BY priority, created_at
    FOR UPDATE SKIP LOCKED
    LIMIT 1
)
UPDATE queue.jobs
SET
  started_at = now(),
  last_heartbeat = now(),
  status = 'started',
  tries = queue.jobs.tries + 1,
  work_signature = uuid_generate_v4()
FROM PEEK
WHERE
  queue.jobs.id = peek_id
RETURNING *;`

type DequeueRow struct {
	ID            int32              `json:"id"`
	QueueID       string             `json:"queue_id"`
	Payload       []byte             `json:"payload"`
	WorkSignature pgtype.UUID        `json:"work_signature"`
	CreatedAt     pgtype.Timestamptz `json:"created_at"`
	LastHeartbeat pgtype.Timestamptz `json:"last_heartbeat"`
	StartedAt     pgtype.Timestamptz `json:"started_at"`
	DoneAt        pgtype.Timestamptz `json:"done_at"`
	Tries         int32              `json:"tries"`
	Priority      int32              `json:"priority"`
	Status        JobStatus          `json:"status"`
	PeekID        int32              `json:"peek_id"`
}

// Dequeue implements Querier.Dequeue.
func (q *DBQuerier) Dequeue(ctx context.Context, queueID string) (DequeueRow, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "Dequeue")
	row := q.conn.QueryRow(ctx, dequeueSQL, queueID)
	var item DequeueRow
	if err := row.Scan(&item.ID, &item.QueueID, &item.Payload, &item.WorkSignature, &item.CreatedAt, &item.LastHeartbeat, &item.StartedAt, &item.DoneAt, &item.Tries, &item.Priority, &item.Status, &item.PeekID); err != nil {
		return item, fmt.Errorf("query Dequeue: %w", err)
	}
	return item, nil
}

// DequeueBatch implements Querier.DequeueBatch.
func (q *DBQuerier) DequeueBatch(batch genericBatch, queueID string) {
	batch.Queue(dequeueSQL, queueID)
}

// DequeueScan implements Querier.DequeueScan.
func (q *DBQuerier) DequeueScan(results pgx.BatchResults) (DequeueRow, error) {
	row := results.QueryRow()
	var item DequeueRow
	if err := row.Scan(&item.ID, &item.QueueID, &item.Payload, &item.WorkSignature, &item.CreatedAt, &item.LastHeartbeat, &item.StartedAt, &item.DoneAt, &item.Tries, &item.Priority, &item.Status, &item.PeekID); err != nil {
		return item, fmt.Errorf("scan DequeueBatch row: %w", err)
	}
	return item, nil
}

const reportDoneSQL = `WITH moved_row AS (
     DELETE FROM queue.jobs
     WHERE
        id = $1 AND
        work_signature = $2 AND
        status = 'started'
     RETURNING *
)
INSERT INTO queue.done_jobs (id, queue_id, payload, created_at, last_heartbeat, done_at, tries, priority)
SELECT
   id,
   queue_id,
   payload,
   created_at,
   last_heartbeat,
   now(),
   tries,
   priority
FROM moved_row;`

// ReportDone implements Querier.ReportDone.
func (q *DBQuerier) ReportDone(ctx context.Context, id int32, workSignature pgtype.UUID) (pgconn.CommandTag, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "ReportDone")
	cmdTag, err := q.conn.Exec(ctx, reportDoneSQL, id, workSignature)
	if err != nil {
		return cmdTag, fmt.Errorf("exec query ReportDone: %w", err)
	}
	return cmdTag, err
}

// ReportDoneBatch implements Querier.ReportDoneBatch.
func (q *DBQuerier) ReportDoneBatch(batch genericBatch, id int32, workSignature pgtype.UUID) {
	batch.Queue(reportDoneSQL, id, workSignature)
}

// ReportDoneScan implements Querier.ReportDoneScan.
func (q *DBQuerier) ReportDoneScan(results pgx.BatchResults) (pgconn.CommandTag, error) {
	cmdTag, err := results.Exec()
	if err != nil {
		return cmdTag, fmt.Errorf("exec ReportDoneBatch: %w", err)
	}
	return cmdTag, err
}

const requeueFailedSQL = `UPDATE queue.jobs
SET
  status = 'ready',
  started_at = null,
  last_heartbeat = null,
  work_signature = null
WHERE
  status = 'started' AND last_heartbeat <= now() - $1::interval;`

// RequeueFailed implements Querier.RequeueFailed.
func (q *DBQuerier) RequeueFailed(ctx context.Context, deadline pgtype.Interval) (pgconn.CommandTag, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "RequeueFailed")
	cmdTag, err := q.conn.Exec(ctx, requeueFailedSQL, deadline)
	if err != nil {
		return cmdTag, fmt.Errorf("exec query RequeueFailed: %w", err)
	}
	return cmdTag, err
}

// RequeueFailedBatch implements Querier.RequeueFailedBatch.
func (q *DBQuerier) RequeueFailedBatch(batch genericBatch, deadline pgtype.Interval) {
	batch.Queue(requeueFailedSQL, deadline)
}

// RequeueFailedScan implements Querier.RequeueFailedScan.
func (q *DBQuerier) RequeueFailedScan(results pgx.BatchResults) (pgconn.CommandTag, error) {
	cmdTag, err := results.Exec()
	if err != nil {
		return cmdTag, fmt.Errorf("exec RequeueFailedBatch: %w", err)
	}
	return cmdTag, err
}

const deleteDeadLettersSQL = `WITH dead_jobs AS (
     DELETE FROM queue.jobs
     WHERE tries >= $1
     RETURNING *
)
INSERT INTO queue.dead_letters (id, queue_id, payload, created_at, last_heartbeat, done_at, tries, priority)
SELECT
  id,
  queue_id,
  payload,
  created_at,
  last_heartbeat,
  done_at,
  tries,
  priority
FROM DEAD_JOBS;`

// DeleteDeadLetters implements Querier.DeleteDeadLetters.
func (q *DBQuerier) DeleteDeadLetters(ctx context.Context, maxTries int32) (pgconn.CommandTag, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "DeleteDeadLetters")
	cmdTag, err := q.conn.Exec(ctx, deleteDeadLettersSQL, maxTries)
	if err != nil {
		return cmdTag, fmt.Errorf("exec query DeleteDeadLetters: %w", err)
	}
	return cmdTag, err
}

// DeleteDeadLettersBatch implements Querier.DeleteDeadLettersBatch.
func (q *DBQuerier) DeleteDeadLettersBatch(batch genericBatch, maxTries int32) {
	batch.Queue(deleteDeadLettersSQL, maxTries)
}

// DeleteDeadLettersScan implements Querier.DeleteDeadLettersScan.
func (q *DBQuerier) DeleteDeadLettersScan(results pgx.BatchResults) (pgconn.CommandTag, error) {
	cmdTag, err := results.Exec()
	if err != nil {
		return cmdTag, fmt.Errorf("exec DeleteDeadLettersBatch: %w", err)
	}
	return cmdTag, err
}

const sendHeartBeatSQL = `UPDATE queue.jobs SET
  last_heartbeat = now()
WHERE
  id = $1 and work_signature = $2 and status = 'started';`

// SendHeartBeat implements Querier.SendHeartBeat.
func (q *DBQuerier) SendHeartBeat(ctx context.Context, id int32, workSignature pgtype.UUID) (pgconn.CommandTag, error) {
	ctx = context.WithValue(ctx, "pggen_query_name", "SendHeartBeat")
	cmdTag, err := q.conn.Exec(ctx, sendHeartBeatSQL, id, workSignature)
	if err != nil {
		return cmdTag, fmt.Errorf("exec query SendHeartBeat: %w", err)
	}
	return cmdTag, err
}

// SendHeartBeatBatch implements Querier.SendHeartBeatBatch.
func (q *DBQuerier) SendHeartBeatBatch(batch genericBatch, id int32, workSignature pgtype.UUID) {
	batch.Queue(sendHeartBeatSQL, id, workSignature)
}

// SendHeartBeatScan implements Querier.SendHeartBeatScan.
func (q *DBQuerier) SendHeartBeatScan(results pgx.BatchResults) (pgconn.CommandTag, error) {
	cmdTag, err := results.Exec()
	if err != nil {
		return cmdTag, fmt.Errorf("exec SendHeartBeatBatch: %w", err)
	}
	return cmdTag, err
}

// textPreferrer wraps a pgtype.ValueTranscoder and sets the preferred encoding
// format to text instead binary (the default). pggen uses the text format
// when the OID is unknownOID because the binary format requires the OID.
// Typically occurs if the results from QueryAllDataTypes aren't passed to
// NewQuerierConfig.
type textPreferrer struct {
	pgtype.ValueTranscoder
	typeName string
}

// PreferredParamFormat implements pgtype.ParamFormatPreferrer.
func (t textPreferrer) PreferredParamFormat() int16 { return pgtype.TextFormatCode }

func (t textPreferrer) NewTypeValue() pgtype.Value {
	return textPreferrer{pgtype.NewValue(t.ValueTranscoder).(pgtype.ValueTranscoder), t.typeName}
}

func (t textPreferrer) TypeName() string {
	return t.typeName
}

// unknownOID means we don't know the OID for a type. This is okay for decoding
// because pgx call DecodeText or DecodeBinary without requiring the OID. For
// encoding parameters, pggen uses textPreferrer if the OID is unknown.
const unknownOID = 0
